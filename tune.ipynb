{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5725c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (4.57.1)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: hf_transfer in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.1.9)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.venv/lib/python3.13/site-packages (from datasets->-r requirements.txt (line 4)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from datasets->-r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.venv/lib/python3.13/site-packages (from datasets->-r requirements.txt (line 4)) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.13/site-packages (from datasets->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.venv/lib/python3.13/site-packages (from datasets->-r requirements.txt (line 4)) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (3.13.2)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 4)) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 4)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 4)) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 4)) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0615169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, enum, time, os, random, math, csv\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch.nn as nn\n",
    "from mask import *\n",
    "from process_data import *\n",
    "from utils import *\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db4244",
   "metadata": {},
   "source": [
    "## Loading in and inspecting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c334b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ffef75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072d4ac",
   "metadata": {},
   "source": [
    "## Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aed3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 or 3. As well as knowing that you can have multiple numbers, you can also do math if you don't already know which key is the right one. After this, the solution will then be stored and processed through the Riemann family for a specific number and we call it the Fibonacci Sequence. Now we will generate the result of the second Fibonacci Sequence with the Fibonacci sequence.\n",
      "\n",
      "function main(string[] args) { var FibonacciSequence\n",
      "---\n",
      "Full output:\n",
      "Help me code up the fibonacci sequence in Python 2 or 3. As well as knowing that you can have multiple numbers, you can also do math if you don't already know which key is the right one. After this, the solution will then be stored and processed through the Riemann family for a specific number and we call it the Fibonacci Sequence. Now we will generate the result of the second Fibonacci Sequence with the Fibonacci sequence.\n",
      "\n",
      "function main(string[] args) { var FibonacciSequence\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Help me code up the fibonacci sequence in Python\"\n",
    "\n",
    "max_new_tokens = 100\n",
    "temperature = 1.0\n",
    "top_k = 50\n",
    "\n",
    "generate_text(model, tokenizer, prompt, device, max_new_tokens, temperature, top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e4ee3",
   "metadata": {},
   "source": [
    "## Loading in txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"OpenCoder-LLM/opc-sft-stage2\", \"educational_instruct\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cdd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = ds.remove_columns([c for c in ds.column_names if c != \"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc975859",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = \"\"\n",
    "for i in range(len(text_ds)):\n",
    "    data1 += text_ds[i]['code']\n",
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[:5337651]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34273d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample_code.txt\", \"w\") as f:\n",
    "    f.write(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ba67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/shakespeare.txt\", \"r\") as f:\n",
    "    data2 = f.read()\n",
    "len(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5994af",
   "metadata": {},
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8798ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = model.config.n_ctx\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04dfc573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1809728 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "paths = ['data/shakespeare.txt']\n",
    "\n",
    "train_ds = SimpleTextDataset(paths, tokenizer, context, DatasetSplit.train)\n",
    "val_ds   = SimpleTextDataset(paths, tokenizer, context, DatasetSplit.valid)\n",
    "test_ds  = SimpleTextDataset(paths, tokenizer, context, DatasetSplit.test)\n",
    "\n",
    "train_loader_1 = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader_1   = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_loader_1  = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e381f738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 11, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader_1), len(val_loader_1), len(test_loader_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1149c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['data/code.txt']\n",
    "\n",
    "train_ds = SimpleTextDataset(paths, tokenizer, context, DatasetSplit.train)\n",
    "val_ds   = SimpleTextDataset(paths, tokenizer, context, DatasetSplit.valid)\n",
    "test_ds  = SimpleTextDataset(paths, tokenizer, context, DatasetSplit.test)\n",
    "\n",
    "train_loader_2 = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader_2   = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_loader_2  = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0176ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 17, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader_2), len(val_loader_2), len(test_loader_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ff518",
   "metadata": {},
   "source": [
    "## Registering Parametrizations, Getting Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19116235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register hooks with split fraction a\n",
    "# active, masks_1, masks_2 = register_hooks(model, a=0.5)\n",
    "controller, masks_1, masks_2 = register_parametrizations(model, a=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36f116",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda89baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, controller, max_batches=None):\n",
    "    controller.set_active(\"ALL\")\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in enumerate(loader, start=1):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(input_ids=x, labels=y)\n",
    "            total_loss += out.loss.item() * x.numel()\n",
    "            total_tokens += x.numel()\n",
    "\n",
    "            if max_batches is not None and step >= max_batches:\n",
    "                break\n",
    "\n",
    "    model.train()\n",
    "    return total_loss / max(1, total_tokens)   # per-token average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da173c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3.5e-4\n",
    "clip = 0.25\n",
    "epochs = 3\n",
    "log_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_D1, params_D2 = [], []\n",
    "for name, p in model.named_parameters():\n",
    "    if name in masks_1:\n",
    "        (params_D1 if \"belongs_to_L1_tensor\" else params_D2).append(p)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "opt1 = torch.optim.Adam(params_D1, lr=lr)\n",
    "opt2 = torch.optim.Adam(params_D2, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ab206",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "CKPT_DIR = f\"checkpoints/{ts}/\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "LOG_EPOCH = os.path.join(CKPT_DIR, \"log.csv\")\n",
    "LOG_STEP = os.path.join(CKPT_DIR, \"steps_raw.csv\")\n",
    "\n",
    "with open(LOG_EPOCH, \"w\") as f:\n",
    "    f.write(\"epoch,elapsed_sec,train_loss1,train_ppl1,train_loss2,train_ppl2,val_loss1,val_ppl1,val_loss2,val_ppl2\\n\")\n",
    "\n",
    "with open(LOG_STEP, \"w\") as f:\n",
    "    f.write(\"global_step,loss1,loss2\\n\")\n",
    "\n",
    "best_val_loss_1 = None\n",
    "best_val_loss_2 = None\n",
    "start_time = time.time()\n",
    "global_step = 0\n",
    "\n",
    "try:\n",
    "    # step-level and log-level accumulators\n",
    "    loss_steps1 = []\n",
    "    loss_steps2 = []\n",
    "    loss_win1   = []\n",
    "    loss_win2   = []\n",
    "    step_index  = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\n===== Epoch {epoch} =====\")\n",
    "        model.train()\n",
    "        t_batch = time.time()\n",
    "\n",
    "        # epoch-level accumulators\n",
    "        train_loss1_tokensum = 0.0\n",
    "        train_loss2_tokensum = 0.0\n",
    "        train_tokens1 = 0\n",
    "        train_tokens2 = 0\n",
    "\n",
    "        eff_train_len = min(len(train_loader_1), len(train_loader_2))\n",
    "\n",
    "        print(f\"{'ep':>3}{'step':>11}{'ms/b':>14}{'lr':>12}\"\n",
    "              f\"{'loss1':>12}{'ppl1':>11}{'loss2':>12}{'ppl2':>11}\")\n",
    "\n",
    "        for step, ((x1, y1), (x2, y2)) in enumerate(zip(train_loader_1, train_loader_2), start=1):\n",
    "            x1, y1 = x1.to(device), y1.to(device)\n",
    "            x2, y2 = x2.to(device), y2.to(device)\n",
    "\n",
    "            # pass 1 (dataset 1)\n",
    "            controller.set_active(\"L1\")\n",
    "            opt1.zero_grad(set_to_none=True)\n",
    "            out1 = model(x1, labels=y1)\n",
    "            out1.loss.backward()\n",
    "            opt1.step()\n",
    "\n",
    "            # pass 2 (dataset 2)\n",
    "            controller.set_active(\"L2\")\n",
    "            opt1.zero_grad(set_to_none=True)\n",
    "            out2 = model(x2, labels=y2)\n",
    "            out2.loss.backward()\n",
    "            opt2.step()\n",
    "\n",
    "            l1 = out1.loss.item()\n",
    "            l2 = out2.loss.item() \n",
    "            loss_steps1.append(l1)\n",
    "            loss_steps2.append(l2)\n",
    "            loss_win1.append(l1)\n",
    "            loss_win2.append(l2)\n",
    "            step_index.append(global_step + 1)\n",
    "\n",
    "            train_loss1_tokensum += l1 * x1.numel()\n",
    "            train_tokens1 += x1.numel()\n",
    "            train_loss2_tokensum += l2 * x2.numel()\n",
    "            train_tokens2 += x2.numel()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            if (step % log_interval) == 0:\n",
    "                elapsed_ms = (time.time() - t_batch) * 1000.0 / log_interval\n",
    "                avg1 = sum(loss_win1) / len(loss_win1)\n",
    "                avg2 = sum(loss_win2) / len(loss_win2)\n",
    "\n",
    "                print(f\"{epoch:3d}{step:7d}/{eff_train_len:<6d}{elapsed_ms:11.2f}{lr:12.1e}\"\n",
    "                      f\"{avg1:12.4f}{math.exp(avg1):11.2f}{avg2:12.4f}{math.exp(avg2):11.2f}\")\n",
    "\n",
    "                loss_win1.clear()\n",
    "                loss_win2.clear()\n",
    "                t_batch = time.time()\n",
    "\n",
    "        # ---------- epoch end aggregates ----------\n",
    "        epoch_train_loss1 = train_loss1_tokensum / max(1, train_tokens1)\n",
    "        epoch_train_loss2 = train_loss2_tokensum / max(1, train_tokens2)\n",
    "        epoch_train_ppl1 = math.exp(epoch_train_loss1)\n",
    "        epoch_train_ppl2 = math.exp(epoch_train_loss2)\n",
    "\n",
    "        # ---------- evaluation AFTER training ----------\n",
    "        t0 = time.time()\n",
    "        eff_val_len = min(len(val_loader_1), len(val_loader_2))\n",
    "        val_loss_1 = evaluate(val_loader_1, model, controller, max_batches=eff_val_len)\n",
    "        val_loss_2 = evaluate(val_loader_2, model, controller, max_batches=eff_val_len)\n",
    "        eval_time = time.time() - t0\n",
    "\n",
    "        print('-' * 100)\n",
    "        print(f'| epoch: {epoch:3d} | eval_time: {eval_time:.2f}s | '\n",
    "              f'val1: {val_loss_1:.3f} (ppl: {math.exp(val_loss_1):.2f}) | '\n",
    "              f'val2: {val_loss_2:.3f} (ppl: {math.exp(val_loss_2):.2f})')\n",
    "        print('-' * 100)\n",
    "\n",
    "        # ---------- checkpointing ----------\n",
    "        # save latest model\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"val_loss_1\": val_loss_1,\n",
    "            \"val_loss_2\": val_loss_2,\n",
    "            \"train_loss_1\": epoch_train_loss1,\n",
    "            \"train_loss_2\": epoch_train_loss2,\n",
    "        }, os.path.join(CKPT_DIR, f\"latest.pt\"))\n",
    "\n",
    "        # save best checkpoints\n",
    "        best_1 = best_val_loss_1 is None or val_loss_1 < best_val_loss_1\n",
    "        best_2 = best_val_loss_2 is None or val_loss_2 < best_val_loss_2\n",
    "\n",
    "        if best_1 or best_2:\n",
    "            if val_loss_1 < best_val_loss_1:\n",
    "                best_val_loss_1 = val_loss_1\n",
    "            if val_loss_2 < best_val_loss_2:\n",
    "                best_val_loss_2 = val_loss_2\n",
    "\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"val_loss_1\": val_loss_1,\n",
    "                \"val_loss_2\": val_loss_2,\n",
    "            }, os.path.join(CKPT_DIR, f\"epoch_{epoch}.pt\"))\n",
    "\n",
    "        # ---------- epoch log row ----------\n",
    "        elapsed_sec = time.time() - start_time\n",
    "        with open(LOG_EPOCH, \"a\") as f:\n",
    "            f.write(f\"{epoch},{elapsed_sec:.2f},\"\n",
    "                    f\"{epoch_train_loss1:.6f},{epoch_train_ppl1:.4f},\"\n",
    "                    f\"{epoch_train_loss2:.6f},{epoch_train_ppl2:.4f},\"\n",
    "                    f\"{val_loss_1:.6f},{math.exp(val_loss_1):.4f},\"\n",
    "                    f\"{val_loss_2:.6f},{math.exp(val_loss_2):.4f}\\n\")\n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(step_index, loss_steps1, label=\"train loss (L1)\")\n",
    "    plt.plot(step_index, loss_steps2, label=\"train loss (L2)\")\n",
    "    plt.xlabel(\"global step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"Training loss vs steps\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CKPT_DIR, \"loss_vs_steps.png\"), dpi=150)\n",
    "    print(f\"Saved plot to {os.path.join(CKPT_DIR, 'loss_vs_steps.png')}\")\n",
    "\n",
    "    with open(LOG_STEP, \"w\") as f:\n",
    "        for s, a, b in zip(step_index, loss_steps1, loss_steps2):\n",
    "            f.write(f\"{s},{a:.6f},{b:.6f}\\n\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Graceful Exit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d315eb1",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/20251106_024828/best.pt\"\n",
    "\n",
    "print(f\"\\n[TEST] Loading checkpoint from: {ckpt_path}\")\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "state_dict = ckpt.get(\"model_state\", ckpt)\n",
    "\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "| TEST @ best_2.pt | loss1: 2.8741 (ppl 17.71) | loss2: 0.6462 (ppl 1.91)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eff_test_len = min(len(test_loader_1), len(test_loader_2))\n",
    "test_loss_1 = evaluate(test_loader_1, model, controller, max_batches=eff_test_len)\n",
    "test_ppl_1  = math.exp(test_loss_1)\n",
    "test_loss_2 = evaluate(test_loader_2, model, controller, max_batches=eff_test_len)\n",
    "test_ppl_2  = math.exp(test_loss_2)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(f\"| TEST @ {os.path.basename(ckpt_path)} | \"\n",
    "      f\"loss1: {test_loss_1:.4f} (ppl {test_ppl_1:.2f}) | \"\n",
    "      f\"loss2: {test_loss_2:.4f} (ppl {test_ppl_2:.2f})\")\n",
    "print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
